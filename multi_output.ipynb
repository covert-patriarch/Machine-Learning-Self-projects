{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_output.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvvqIrmtY2e3",
        "outputId": "810bc25b-1853-463f-80d0-2402da13e874"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQZcpOJCcjYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e9096d-0823-41e3-8b4a-3492f1113c6f"
      },
      "source": [
        "####### the multi output selection code\n",
        "data= []\n",
        "\n",
        "with open(\"dino.txt\") as f:\n",
        "  data = f.readlines()\n",
        "\n",
        "print(data[:10])\n",
        "oov_token = 'oov'\n",
        "num_words = 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Aachenosaurus\\n', 'Aardonyx\\n', 'Abdallahsaurus\\n', 'Abelisaurus\\n', 'Abrictosaurus\\n', 'Abrosaurus\\n', 'Abydosaurus\\n', 'Acanthopholis\\n', 'Achelousaurus\\n', 'Acheroraptor\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI6iRYW6dHsT"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDhmcuxxd3rQ",
        "outputId": "bd764468-a8cb-405c-bc82-536d0c923593"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words,char_level=True)\n",
        "tokenizer.fit_on_texts(data)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 1, 's': 2, 'u': 3, 'o': 4, 'r': 5, '\\n': 6, 'n': 7, 'i': 8, 'e': 9, 't': 10, 'l': 11, 'p': 12, 'h': 13, 'c': 14, 'g': 15, 'd': 16, 'm': 17, 'y': 18, 'b': 19, 'k': 20, 'v': 21, 'x': 22, 'z': 23, 'j': 24, 'w': 25, 'f': 26, 'q': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz9QQV01egBw",
        "outputId": "fbe47885-ccbb-4f63-af91-86f7fa1de341"
      },
      "source": [
        "data_seq = tokenizer.texts_to_sequences(data)\n",
        "print(data[0])\n",
        "print(data_seq[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aachenosaurus\n",
            "\n",
            "[1, 1, 14, 13, 9, 7, 4, 2, 1, 3, 5, 3, 2, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCIobOVmfeVY",
        "outputId": "7857d777-03a3-417a-fcb9-16be05c4afa1"
      },
      "source": [
        "inp_X = []\n",
        "inp_Y = []\n",
        "\n",
        "for seq in data_seq :\n",
        "  for i in range(len(seq)-1):\n",
        "    inp_X.append(seq[:i+1])\n",
        "    inp_Y.append(seq[1:i+2])\n",
        "#print(inp_X)\n",
        "#print(inp_Y)\n",
        "\n",
        "print(len(inp_X),len(inp_Y))\n",
        "print(inp_X[1],inp_Y[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18373 18373\n",
            "[1, 1] [1, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQU7zpK3i_EJ",
        "outputId": "7056d6c4-b4dc-4ee5-d989-6487e27b032a"
      },
      "source": [
        "maxlen = max([len(seq) for seq in inp_X])\n",
        "print(maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuiWDQa5kPHo",
        "outputId": "4eec95a5-6c2e-453c-c051-b65ff6b59a45"
      },
      "source": [
        "train_X = pad_sequences(inp_X,maxlen)\n",
        "train_Y = pad_sequences(inp_Y,maxlen)\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18373, 26)\n",
            "(18373, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKHpYd_qerFH"
      },
      "source": [
        "input = layers.Input(shape=(None,))\n",
        "embedding_out = layers.Embedding(input_dim=num_words,output_dim=5)(input)\n",
        "rnn_out,state_h,state_c = layers.LSTM(50,return_sequences=True,return_state=True)(embedding_out)\n",
        "output = layers.Dense(30,activation='softmax')(rnn_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p1fO_M7iNks",
        "outputId": "ef1aafd1-de4e-4b58-c45c-cdbc916968a8"
      },
      "source": [
        "model = tf.keras.Model(input,output)\n",
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, None, 5)           150       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                [(None, None, 50), (None, 11200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, None, 30)          1530      \n",
            "=================================================================\n",
            "Total params: 12,880\n",
            "Trainable params: 12,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA6TkTCclFf4",
        "outputId": "c060d970-3d8e-4c3d-9704-2f797261f521"
      },
      "source": [
        "model.fit(train_X[:10000],train_Y[:10000],epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 3s 5ms/step - loss: 1.7556 - accuracy: 0.7264\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.7459 - accuracy: 0.7776\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6705 - accuracy: 0.7919\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6214 - accuracy: 0.8113\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5977 - accuracy: 0.8189\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5704 - accuracy: 0.8244\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5621 - accuracy: 0.8264\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5473 - accuracy: 0.8312\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5427 - accuracy: 0.8321\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5274 - accuracy: 0.8355\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5228 - accuracy: 0.8367\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5220 - accuracy: 0.8375\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5147 - accuracy: 0.8400\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5132 - accuracy: 0.8405\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5046 - accuracy: 0.8428\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5044 - accuracy: 0.8429\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4983 - accuracy: 0.8444\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4977 - accuracy: 0.8446\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4936 - accuracy: 0.8453\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4894 - accuracy: 0.8464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc54a421850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6G0M0Q_4AGp",
        "outputId": "25ca5a9b-8e0f-44e0-ac55-36c74dbec213"
      },
      "source": [
        "test_X = np.array(train_X[25])\n",
        "print(test_X.shape)\n",
        "test_X = np.reshape(test_X,[1,-1])\n",
        "print(test_X.shape)\n",
        "res = model.predict(test_X)\n",
        "print(res.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26,)\n",
            "(1, 26)\n",
            "(1, 26, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubtnLc_MFe6o",
        "outputId": "58d8d9ff-92ce-493b-c54a-814272fef8ca"
      },
      "source": [
        "sample = model.layers[1](test_X)\n",
        "print(sample.shape)\n",
        "sample_2,state_h,state_c = model.layers[2](sample)\n",
        "sample_3 = model.layers[3](sample_2)\n",
        "print(sample_2.shape)\n",
        "print(state_h.shape,state_c.shape)\n",
        "print(sample_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 26, 5)\n",
            "(1, 26, 50)\n",
            "(1, 50) (1, 50)\n",
            "(1, 26, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65uB22LKBBox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bbfd23-6e96-4426-f865-03cdf091f4b4"
      },
      "source": [
        "rev_sample = tokenizer.sequences_to_texts(test_X)\n",
        "print(rev_sample)\n",
        "print(test_X)\n",
        "\n",
        "print(sample_3)\n",
        "print(np.argmax(sample_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a b d a l']\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 19 16\n",
            "   1 11]]\n",
            "tf.Tensor(\n",
            "[[3.5107674e-12 8.2286970e-05 3.6094137e-03 2.6167643e-05 2.9124146e-02\n",
            "  6.4744152e-02 1.1015487e-06 2.8948888e-02 6.0967356e-03 3.7313244e-04\n",
            "  7.0089186e-03 8.0798131e-01 5.2713098e-05 4.0368942e-04 5.5132178e-03\n",
            "  3.2131058e-05 1.9257027e-04 8.6125219e-03 5.3172791e-04 1.2096987e-03\n",
            "  3.5049975e-02 1.4663447e-04 6.2865379e-06 8.1919425e-05 2.4894337e-06\n",
            "  4.8081401e-05 1.2012369e-04 1.0039261e-07 3.6516228e-12 5.6560468e-12]], shape=(1, 30), dtype=float32)\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq3jL8ZmtuyA",
        "outputId": "3a3d2406-11ef-4744-fb63-6e7b1af31f8f"
      },
      "source": [
        "seed_text = [\"H\"]\n",
        "\n",
        "i = 0\n",
        "next_char = seed_text\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(seed_text)\n",
        "\n",
        "print(test_seq)\n",
        "test_seq = np.array(test_seq)\n",
        "#test_seq = np.reshape(test_seq,[1,-1)\n",
        "test_out1 = model.layers[1](test_seq)\n",
        "print(test_out1.shape)\n",
        "test_out2,state_h,state_c = model.layers[2](test_out1)\n",
        "test_out3 = model.layers[3](test_out2)\n",
        "print(test_out3.shape,state_h.shape,state_c.shape)\n",
        "\n",
        "predicted = np.argmax(test_out3)\n",
        "\n",
        "test_seq2 = tokenizer.sequences_to_texts([[predicted]])\n",
        "print(test_seq2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13]]\n",
            "(1, 1, 5)\n",
            "(1, 30) (1, 50) (1, 50)\n",
            "['p']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BLioualxM-k",
        "outputId": "fe631d6e-2654-4136-efcf-88a519161114"
      },
      "source": [
        "\n",
        "i = 0\n",
        "seed_text = [\"megold\"]\n",
        "result = seed_text[0]\n",
        "next_char = seed_text\n",
        "while next_char[0] != '\\n':\n",
        "\n",
        "  test_seq = tokenizer.texts_to_sequences(next_char)\n",
        "  test_seq = np.array(test_seq)\n",
        "  embedding_out =model.layers[1](test_seq)\n",
        "  if (i == 0):\n",
        "    state_h,state_c = model.layers[2].get_initial_state(embedding_out)\n",
        "  \n",
        "  lstm_out,state_h,state_c = model.layers[2](embedding_out,initial_state = [state_h,state_c])\n",
        "  dense_out = model.layers[3](lstm_out[:,-1,:])\n",
        "\n",
        "  char_id = np.argmax(dense_out)\n",
        "  next_char = tokenizer.sequences_to_texts([[char_id]])\n",
        "  #print(next_char)\n",
        "  result += next_char[0]\n",
        "\n",
        "  print(result)\n",
        "  i = i+1\n",
        "  #if(i >40):\n",
        "  #  break\n",
        "\n",
        "  if(next_char[0] =='\\n'):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "megoldo\n",
            "megoldos\n",
            "megoldosa\n",
            "megoldosau\n",
            "megoldosaur\n",
            "megoldosauru\n",
            "megoldosaurus\n",
            "megoldosaurus\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}